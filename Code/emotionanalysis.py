# -*- coding: utf-8 -*-
"""EmotionAnalysis

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wRnFz995VQiuTMSMk3ah8Z9Wfo52dQNt
"""

from google.colab import drive
drive.mount("/content/drive")

!pip uninstall -y torch torchvision torchaudio numpy
!pip install numpy==1.26.4 --quiet
!pip install torch==2.1.0 torchvision==0.16.0 torchaudio==2.1.0 --index-url https://download.pytorch.org/whl/cu118
!pip install transformers datasets emoji unidecode ftfy --quiet

import torch
import numpy as np

print("Torch version:", torch.__version__)
print("Numpy version:", np.__version__)
print("Torch tensor to numpy works:", torch.tensor([1.0]).numpy())

import pandas as pd
import os

import re
import emoji
from unidecode import unidecode

from datasets import Dataset
import numpy as np

import seaborn as sns
import matplotlib.pyplot as plt

import matplotlib.dates as mdates

twibot_csv = '/content/drive/MyDrive/Twibot22Split/tweet_7-006_humans.csv'

tweets_df = (
    pd.read_csv(twibot_csv, parse_dates=['created_at'])
      .dropna(subset=['text'])
      .astype({'text': str})
)

tweets_df.rename(columns={'created_at': 'timestamp'}, inplace=True)

print(f"Loaded TwiBot tweet count: {len(tweets_df)}")
tweets_df.head()

def clean_tweet(text):
    text = unidecode(text)
    text = emoji.replace_emoji(text, replace='')
    text = re.sub(r'http\S+|@\w+|#\w+', '', text)
    text = re.sub(r'[^A-Za-z0-9\s]', '', text)
    return text.lower().strip()

tweets_df['clean_text'] = tweets_df['text'].apply(clean_tweet)

from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline

model_name = "cardiffnlp/twitter-roberta-base-emotion"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSequenceClassification.from_pretrained(model_name)

twitter_emotion_pipe = pipeline("text-classification", model=model, tokenizer=tokenizer, top_k=None)

hf_dataset = Dataset.from_pandas(tweets_df[['clean_text']].dropna().reset_index(drop=True))

def get_twitter_emotions(batch):
    results = twitter_emotion_pipe(batch['clean_text'], batch_size=32, truncation=True)
    return {'twitter_emotions': results}

hf_dataset = hf_dataset.map(get_twitter_emotions, batched=True)

def flatten_twitter_emotions(emotion_list):
    return {item['label']: item['score'] for item in emotion_list}

flat_emotions = pd.DataFrame([flatten_twitter_emotions(e) for e in hf_dataset['twitter_emotions']])
tweets_df = pd.concat([tweets_df.reset_index(drop=True), flat_emotions], axis=1)

tweets_df['timestamp'] = pd.to_datetime(tweets_df['timestamp'], errors='coerce')
tweets_df = tweets_df.dropna(subset=['timestamp'])
tweets_df['year_month'] = tweets_df['timestamp'].dt.to_period('M').astype(str)

output_path = '/content/drive/MyDrive/twibot22_results/tweet_7-006_humans_roberta_emotions.csv'
tweets_df.to_csv(output_path, index=False)
print(f"Saved to: {output_path}")